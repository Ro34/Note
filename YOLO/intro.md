# YOLO系列
### IOU计算指标
#### 指标分析
1. MAP指标：综合衡量检测效果
2. IOU：area_of_Overlab/area_of_Union
ground_truth与Prediction 交集和并集的比值
    > recall：所有物体是不是都检测到了
    > 精度：每一个物体检测的效果
#### 评估所需参数计算
精度 Precision = TP/(TP+FP) 错判
召回率（查全率）Recall = TP/(TP+FN) 漏判

| | 相关，正类 | 无关，负类|
| ---| ---|---|
| 被检索到P| TP，正类判定正类|FP，负类判定正类,存伪|
|未被检索到N|FN，正类判定为负类，去真|TN,负类判定负类|
#### 指标计算
置信度：判断为正例的可能性（把握）
置信度阈值
mAP：精确率召回率图下方围城的面积，取精度最大值
## YOLOv1
### 过程
1. 输入s*s
2. 两种候选框
3. 计算IoU
4. x,y,w,h,c
5. 过滤置信度低的
6. 算出最终框

### 网络架构
1. 输入448 * 448 * 3
2. 多次卷积
3. 7 * 7 * 1024
4. 全连接
5. 7 * 7 * 30
   > 7*7格子，有30个值
   > 每个格子两种框，每个框5个参数，剩下20个参数为20分类
6. 最终输出（S✖️S)✖️(B✖️5➕C)
### 位置损失计算
### 置信度误差与优缺点分析
小物体无法检测
重叠无法检测
多标签无法实现
### NMS
非极大值抑制
按置信度排序，只选择极大值

## YOLOv2
### 提升
#### BN
1. 舍弃Dropout，卷积后加入Batch Normalization
2. 网络每一层输入做归一化，收敛相对容易
3. BN会提升2%mAP
4. 标配BN
#### 分辨率
1. 训练时进行10次448*448的微调
2. mPA提升4%
### 网络结构
1. DarkNet19 输入416*416
2. 没有全连接层，5次降采样（13*13），gridsize
3. 1*1卷积节省参数
### 聚类提取先验框
k-means聚类
距离 d(box,centroids)=1-IoU(box,centroids)
### Anchor Box
召回率增加（查全率）
### Direction Location Prediction
1. v1: bbox x=xp+wp\*tx,y=yp+hp\*ty
2. 刚开始训练的时候，模型不稳定，收敛问题
3. V2中没有直接使用偏移量，选择相对gridcell的偏移量
4. v2计算公式 bx=sigmoid(tx)+cx，bw=pw\*e^(tw)
   预测值tx,ty,tw,th，先验框pw,ph
### 感受野
最后的特征图中一个点，相当于原始input中多大的区域，即为感受野
越大的感受野越能感受全局
堆叠小卷积核需要的参数更少一些
卷积过程越多，特征提取越细致
### Fine-Grained Feature
最后一层感受野太大了，小目标可能丢失了，需要融合之前的特征
### Multi Scale 多尺度检测
一定迭代（iterations）之后改变输入图像大小
## YOLOv3
1. 改进网络结构，适合小目标检测
2. 特征更细节，融入多持续特征图信息来预测不同规格
3. 先验框总共3\*3=9种
4. softmax改进，预测多标签任务
### 多scale
scale变换经典方法
图像金字塔|单一的输入
对不同的特征图分别利用|不同特征图融合后进行预测-上采样
### 残差连接-为了更好地特征
堆叠更多地层来进行特征提取
### 核心网络架构
1. 没有池化和全连接层，全部卷积
2. 下采样通过stride为2实现
3. 3种scale，更多先验框
4. 基本上当下经典做法全融入了
### softmax层代替
logistic激活函数来完成，这样就能预测每一个类别是/不是
